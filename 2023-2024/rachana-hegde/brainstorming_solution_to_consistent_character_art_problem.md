**Problem to solve: Writer’s block!**

**Research challenge #1:** There is no consistency across images of characters when they appear in different settings and scenarios. This is an issue for storyboarding because the same character will look different in different scenes and this can be confusing for the writer – makes it harder for them to visualise the narrative.

**Solution:**

- First, the writer will generate some images for the main cast of character (3-7 individuals) and iterate until they are satisfied with the character art. They will keep adjusting the prompt (implement prompt suggestions, etc.) until the images are suitable.
    - Can make it possible to search for images through popular image search APIs to get inspiration THEN get captions for the images from the API to help generate more specific images using the generative image model.
    - API options:
        - Pinterest API – possibly FREE
        - [Unsplash API](https://unsplash.com/developers) – FREE, default rate limit of 50 requests per hour
        - [Bing image search API](https://www.microsoft.com/en-us/bing/apis/pricing) – possibly FREE
        - [Custom Search JSON API](https://console.cloud.google.com/marketplace/product/google/customsearch.googleapis.com?pli=1) (for searching google images) provides 100 search queries per day for free.
    - Can also create a pipeline where multiple images are generated behind the scenes along with captions and the image with caption that aligns most closely with the original user prompt is displayed to user (or images are generated until caption and prompt alignment is improved). Can also iteratively edit prompt to emphasise or add weight to the details that are missing from the image BEFORE displaying image to user.
- Next, find a way to ensure that these characters will appear the same in images generated by the SD model for the storyboard – i.e. main character fishing or main character doing grocery shopping has to look the same in both scenarios.
    - SDXL will be finetuned on the dataset of character art (the batch of images that the user is satisfied with) and this could help ensure consistency. Can use RLHF for this.
    - Associate character names with image prompts that describe those characters – not sure how to get SD to remember who looks like what though.
    - Need to look at papers on tuning SDXL for consistency in multiple images or how prompt tuning & prompt engineering or fine tuning LLMs can be used for improving SDXL results.

Note: Each time a person uses the application, they create a new cast of characters – so a new diffusion model is finetuned for their purpose. I need to facilitate that process so the user doesn’t have to do anything technical on their end.

**I need to look for existing research on this topic and list some different strategies and the extent to which they worked and their limitations…think about how I can modify them for my own project.**

**I need to learn more about finetuning and working with diffusion models.**

**Second research challenge:** Making it possible to edit images without the model generating the entire image completely from scratch – i.e. user specifying which aspects of the image should be corrected and consequently getting more accurate character or setting art. This is currently easier to achieve with settings (provided you are a little flexible with your imagination) and more difficult with people who have unconventional appearances or if your description of the character is too detailed. **The challenge here would be improving the accuracy of the generated images (particularly prompt adherence).**

## Other problems that need solving

- If I’m trying to generate images of a scene, it produces the incorrect number of people, messes up their appearance, duplicates individuals, doesn’t include finer details like certain objects. **Make it possible to generate highly detailed images of settings containing multiple people performing specific actions. (Could create a pipeline where the model produces captions of the image and if there are details missing in that caption, then a new prompt and image pair is produced until it’s a little more accurate and can be shown to the user.)**
    - Also Dall E has trouble keeping track of people – there’s 5 individuals in many of the scene images instead of the 4 people described in the prompt. – something that multiple papers have mentioned trying to solve
- It also gets confused about clothing and ethnicity even if these are specified in the prompt. If the ethnicity is specified as Indian, it’ll generate people wearing traditional Indian attire (saree, lungi, etc.) or non-Western clothing so it leans towards stereotypes and assumptions.
- Details in the image background (the people and objects) need to be rendered more accurately.
- SDXL images need to be higher quality – this has been solved, I think it depends on the prompt and the model settings (or which model is used)
