# Notes on Research Papers 
## LLMs for Creative Writing
## ****End-to-end Story Plot Generator****
[Link](https://arxiv.org/abs/2310.08796), Oct 2023 (Preprint)

- [Paper summary from Twitter](https://twitter.com/tydsh/status/1720124757084098898): It can generate a complete story plot with 1,000+ tokens, including setting, characters, outlines, in less than 30 seconds, and can be further fine-tuned for different goals. It is based on our previous story generation paper ([https://arxiv.org/abs/2212.10077](https://t.co/Fnj5gl2oqj)), but is much faster and does not require hundreds of OpenAI API calls. Code and data are open sourced.
- Code available here: https://github.com/facebookresearch/doc-storygen-v2
- From Abstract: We study the problem of auto- matic generation of story plots, which includes story premise, character descrip- tions, plot outlines, etc. To generate a single engaging plot, existing plot gen- erators (e.g., DOC (Yang et al., 2022a)) require hundreds to thousands of calls to LLMs (e.g., OpenAI API) in the planning stage of the story plot, which is costly and takes at least several minutes. Moreover, the hard-wired nature of the method makes the pipeline non-differentiable, blocking fast specialization and personalization of the plot generator. In this paper, we propose three models, OpenPlot, E2EPlot and RLPlot, to address these challenges. OpenPlot replaces expensive OpenAI API calls with LLaMA2 (Touvron et al., 2023) calls via careful prompt designs, which leads to inexpensive generation of high-quality training datasets of story plots. We then train an end-to-end story plot genera- tor, E2EPlot, by supervised fine-tuning (SFT) using approximately 13000 story plots generated by OpenPlot. E2EPlot generates story plots of comparable quality to OpenPlot, and is > 10× faster (1k tokens in only 30 seconds on aver- age). Finally, we obtain RLPlot that is further fine-tuned with RLHF on several different reward models for different aspects of story quality, which yields 60.0% winning rate against E2EPlot along the aspect of suspense and surprise.
- To generate high-quality story plot datasets for training the end-to-end model as well as the reward models, we need a hard-wired pipeline to generate story plots by repeatedly prompting LLMs.
- Our pipeline for generating training datasets follows Yang et al. (2022a) while replacing OpenAI API calls with the Llama2 model, which eliminates the rate limit and makes large batch generation feasible.
- Note that although our end-to-end generator is totally automatic without human intervention, it is easy for humans to co-create after the plot generation stage. Since the story plot is relatively short and thus easy for humans to evaluate, one can easily edit the plot to obtain a more desired story.
- Future work – For example, **the current generation speed is around 30 seconds, which is still somewhat slow from a user experience perspective.** It might be possible to incorporate techniques for more efficient inference such as Zhang et al. (2023) into our end-to-end model. Also, since the previous DOC pipeline has more flexibility for controlling the level of granularity, it would be appealing to train an end-to-end model that inherits this property. Additionally, a high-quality reward model is important to improve the end-to-end generator.
- **I can’t implement this exact solution  even if they have provided the code. But there is useful information about how they designed and structured prompts to generate information about premise, characters, etc. from the LLM.** I.e. “*Moreover, the output of Llama2 focuses more on the age and appearance of the character instead of occupation, experiences, or relationships with other characters (e.g., “Tom is 22 years old and has brown curly hair”). Therefore, we add detailed instructions on generating portraits such as “focusing on relationship between characters, occupation and experience instead of appearance” to ensure the generated portraits contain more useful information about the character.*
